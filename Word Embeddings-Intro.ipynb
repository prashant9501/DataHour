{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9_NbqIFzdjR"
   },
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fweGuN6lzdjT"
   },
   "source": [
    "A word embedding is a class of approaches for representing words and documents using a\n",
    "dense vector representation. It is an improvement over more the traditional bag-of-word model\n",
    "encoding schemes where large sparse vectors were used to represent each word or to score each\n",
    "word within a vector to represent an entire vocabulary. These representations were sparse\n",
    "because the vocabularies were vast and a given word or document would be represented by a\n",
    "large vector comprised mostly of zero values.\n",
    "\n",
    "Instead, in an embedding, words are represented by dense vectors where a vector represents\n",
    "the projection of the word into a continuous vector space. The position of a word within the\n",
    "vector space is learned from text and is based on the words that surround the word when it is\n",
    "used. The position of a word in the learned vector space is referred to as its embedding. Two\n",
    "popular examples of methods of learning word embeddings from text include:\n",
    "+ Word2Vec.\n",
    "+ GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCNbkJ8nzdjU"
   },
   "source": [
    "In addition to these carefully designed methods, a word embedding can be learned as part\n",
    "of a deep learning model. This can be a slower approach, but tailors the model to a specific\n",
    "training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5016,
     "status": "ok",
     "timestamp": 1589017728346,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "LaNyL1TfzdjW",
    "outputId": "c4d0ed44-cf4f-4476-9222-ee9252c85628"
   },
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmE9pD2Yzdjb"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "        ['this', 'is', 'the', 'second', 'sentence'],\n",
    "        ['yet', 'another', 'sentence'],\n",
    "        ['one', 'more', 'sentence', 'love'],\n",
    "        ['and', 'the', 'final', 'sentence', 'solve']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1_3E4LFzdjg"
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "cbow_model = Word2Vec(sentences, vector_size = 10, window = 3, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1589018024207,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "78cr9Oiizdjl",
    "outputId": "cf417730-ef5b-4d7b-c4f3-f7a734aee491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=16, vector_size=10, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded model\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence',\n",
       " 'the',\n",
       " 'is',\n",
       " 'this',\n",
       " 'solve',\n",
       " 'final',\n",
       " 'and',\n",
       " 'love',\n",
       " 'more',\n",
       " 'one',\n",
       " 'another',\n",
       " 'yet',\n",
       " 'second',\n",
       " 'word2vec',\n",
       " 'for',\n",
       " 'first']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cbow_model.wv.key_to_index.keys())   # this is the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1589018031026,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "09OPrZ1Kzdjx",
    "outputId": "dd8848cf-1d65-4892-cbdf-1fd5b6eab91d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05455598,  0.08345091, -0.0145442 , -0.09208831,  0.04371774,\n",
       "        0.00572208,  0.07440059, -0.00813585, -0.0263755 , -0.08752632],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access vector for one word\n",
    "cbow_model.wv.get_vector('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1191,
     "status": "ok",
     "timestamp": 1589018036845,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "zzGb1LPPzdj_",
    "outputId": "16376298-c7e7-43b6-8f52-16bbf8180720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : [-0.00536351  0.00238484  0.05107331  0.09015599 -0.09308276 -0.0711995\n",
      "  0.06464671  0.08974326 -0.0501915  -0.03765175]\n",
      "the : [ 0.07379383 -0.01529509 -0.04534442  0.06555367 -0.04861008 -0.0181848\n",
      "  0.02882639  0.00993654 -0.08292154 -0.0944667 ]\n",
      "is : [ 0.07311766  0.05070262  0.06757693  0.00762866  0.06350891 -0.03405366\n",
      " -0.00946401  0.05768573 -0.07521638 -0.03936104]\n",
      "this : [-0.07512096 -0.00929068  0.09539422 -0.07316343 -0.02336625 -0.01939589\n",
      "  0.08080077 -0.0592867   0.00042713 -0.04753667]\n",
      "solve : [-0.09603605  0.05007694 -0.08758304 -0.04394896 -0.00034404 -0.00295622\n",
      " -0.07661133  0.09616364  0.04980589  0.09235525]\n",
      "final : [-0.08158192  0.04498189 -0.04134833  0.00827747  0.08496136 -0.04464175\n",
      "  0.04521902 -0.06785722 -0.03552099  0.09398862]\n",
      "and : [-0.0157806   0.00323172 -0.04137019 -0.0768177  -0.01509309  0.02468751\n",
      " -0.00885536  0.05536246 -0.02745937  0.02261946]\n",
      "love : [ 0.05455598  0.08345091 -0.0145442  -0.09208831  0.04371774  0.00572208\n",
      "  0.07440059 -0.00813585 -0.0263755  -0.08752632]\n",
      "more : [-0.00856507  0.02827049  0.05402207  0.07053649 -0.05704191  0.01858408\n",
      "  0.06090086 -0.04797724 -0.03107981  0.06797591]\n",
      "one : [ 0.01631279  0.00189054  0.03472958  0.00217089  0.09620048  0.05061027\n",
      " -0.08919239 -0.07041863  0.0090232   0.06392911]\n",
      "another : [-0.086186    0.03666105  0.05190048  0.05741437  0.07469033 -0.06168002\n",
      "  0.01105572  0.0604757  -0.02841936 -0.06173667]\n",
      "yet : [-0.00410223 -0.08368949 -0.05600012  0.07104538  0.0335254   0.0722567\n",
      "  0.06800248  0.07530741 -0.03789154 -0.00561806]\n",
      "second : [ 0.02348792 -0.04518132  0.08388387 -0.09859845  0.06765947  0.0291517\n",
      " -0.04933304  0.04398151 -0.01739845  0.06711598]\n",
      "word2vec : [ 0.0996485  -0.04362444 -0.00599338 -0.05695637  0.03850823  0.02786627\n",
      "  0.06891076  0.06101096  0.09538497  0.09273417]\n",
      "for : [ 0.07898068 -0.06989504 -0.09155865 -0.00355753 -0.03099841  0.07894317\n",
      "  0.05938574 -0.01545663  0.01510963  0.01790041]\n",
      "first : [ 0.07817571 -0.09510187 -0.00205531  0.03469197 -0.00938972  0.08381772\n",
      "  0.09010784  0.06536506 -0.00711621  0.07710405]\n"
     ]
    }
   ],
   "source": [
    "for key in cbow_model.wv.key_to_index.keys():\n",
    "    print(key, ':', cbow_model.wv.get_vector(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 643,
     "status": "error",
     "timestamp": 1589017925913,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "xIc5a3W72RB3",
    "outputId": "501d9500-341c-44e8-b6b7-c122aaf4ca0a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'analytics' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcbow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalytics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\gensim\\models\\keyedvectors.py:447\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\gensim\\models\\keyedvectors.py:421\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'analytics' not present\""
     ]
    }
   ],
   "source": [
    "cbow_model.wv.get_vector('analytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzvvbATPzdkH"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "cbow_model.save('model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "error",
     "timestamp": 1589018068869,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "amU0o9fgzdkL",
    "outputId": "e633c198-d940-4539-f70b-71ce0fb60965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=16, vector_size=10, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05455598,  0.08345091, -0.0145442 , -0.09208831,  0.04371774,\n",
       "        0.00572208,  0.07440059, -0.00813585, -0.0263755 , -0.08752632],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.get_vector('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1589018095755,
     "user": {
      "displayName": "Prashant Sahu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgpWHtnVqeOz3R8ZN_aCneM4Ys0mkXEOSqeXNpi7A=s64",
      "userId": "17861245123904241513"
     },
     "user_tz": -330
    },
    "id": "FIkrgSY0zdkO",
    "outputId": "38a3caac-577c-4fd9-b9db-da86102c3612"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05455508,  0.08348128, -0.01442463, -0.09193361,  0.04362334,\n",
       "        0.00568476,  0.07447571, -0.00811199, -0.02645334, -0.0874837 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model = Word2Vec(sentences, vector_size=10, window = 3, min_count=1, sg=1)\n",
    "\n",
    "# access vector for one word\n",
    "sg_model.wv.get_vector('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_EqwX-9zdkV"
   },
   "outputs": [],
   "source": [
    "# [ 0.05455598,  0.08345091, -0.0145442 , -0.09208831,  0.04371774,\n",
    "#         0.00572208,  0.07440059, -0.00813585, -0.0263755 , -0.08752632],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Cuz5UOozdlA"
   },
   "source": [
    "### Some computations using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFUUhgfJzdlB"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the google word2vec model\n",
    "path = r'D:\\OneDrive\\Google Drive Files\\Training\\1 MASTER\\NLP Master\\Word Embedding\\WV -1'\n",
    "filename = path + r'\\GoogleNews-vectors-negative300.bin'\n",
    "# filename = r'C:\\Users\\dell\\Google Drive\\DUMP\\Desktop\\Nomura NLP\\Word Embedding\\WV -1\\GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00524902, -0.14355469, -0.06933594,  0.12353516,  0.13183594,\n",
       "       -0.08886719, -0.07128906, -0.21679688, -0.19726562,  0.05566406,\n",
       "       -0.07568359, -0.38085938,  0.10400391, -0.00081635,  0.1328125 ,\n",
       "        0.11279297,  0.07275391, -0.046875  ,  0.06591797,  0.09423828,\n",
       "        0.19042969,  0.13671875, -0.23632812, -0.11865234,  0.06542969,\n",
       "       -0.05322266, -0.30859375,  0.09179688,  0.18847656, -0.16699219,\n",
       "       -0.15625   , -0.13085938, -0.08251953,  0.21289062, -0.35546875,\n",
       "       -0.13183594,  0.09619141,  0.26367188, -0.09472656,  0.18359375,\n",
       "        0.10693359, -0.41601562,  0.26953125, -0.02770996,  0.17578125,\n",
       "       -0.11279297, -0.00411987,  0.14550781,  0.15625   ,  0.26757812,\n",
       "       -0.01794434,  0.09863281,  0.05297852, -0.03125   , -0.16308594,\n",
       "       -0.05810547, -0.34375   , -0.17285156,  0.11425781, -0.09033203,\n",
       "        0.13476562,  0.27929688, -0.04980469,  0.12988281,  0.17578125,\n",
       "       -0.22167969, -0.01190186,  0.140625  , -0.18164062,  0.11865234,\n",
       "        0.16113281,  0.21484375, -0.21191406,  0.12695312, -0.10009766,\n",
       "        0.13671875,  0.12695312,  0.01531982,  0.10449219, -0.02783203,\n",
       "       -0.06030273,  0.0222168 ,  0.18164062, -0.06738281,  0.04907227,\n",
       "        0.15429688, -0.25      ,  0.13964844,  0.29492188,  0.10644531,\n",
       "        0.3359375 , -0.22265625, -0.125     , -0.05297852,  0.19238281,\n",
       "        0.06835938,  0.06982422, -0.05200195,  0.14453125,  0.00448608,\n",
       "       -0.01013184, -0.1484375 ,  0.21777344, -0.1953125 , -0.390625  ,\n",
       "        0.07763672, -0.57421875, -0.07910156, -0.04052734, -0.1875    ,\n",
       "        0.25390625,  0.15722656,  0.125     ,  0.140625  ,  0.20117188,\n",
       "       -0.05859375,  0.16894531, -0.28125   ,  0.171875  ,  0.19140625,\n",
       "        0.12109375, -0.15039062, -0.00695801, -0.23730469,  0.13964844,\n",
       "       -0.00836182, -0.04711914,  0.14648438, -0.05688477,  0.10205078,\n",
       "        0.08447266,  0.21191406, -0.01831055,  0.50390625, -0.04858398,\n",
       "        0.22167969, -0.25585938,  0.03417969,  0.15820312, -0.03369141,\n",
       "        0.06738281, -0.25195312,  0.04614258, -0.07275391,  0.07958984,\n",
       "        0.04223633, -0.00128937,  0.20214844, -0.13085938, -0.06030273,\n",
       "        0.0378418 ,  0.13574219,  0.11181641, -0.24609375, -0.23925781,\n",
       "       -0.23632812, -0.04321289, -0.02905273,  0.23535156, -0.00390625,\n",
       "       -0.05029297,  0.18457031,  0.50390625, -0.00668335, -0.03466797,\n",
       "       -0.07568359,  0.06152344, -0.31445312, -0.03759766,  0.23632812,\n",
       "       -0.12792969,  0.15429688,  0.296875  ,  0.02709961, -0.17089844,\n",
       "       -0.22460938,  0.00241089,  0.10595703, -0.03320312,  0.0145874 ,\n",
       "       -0.21582031,  0.24707031, -0.07421875, -0.10205078,  0.16894531,\n",
       "       -0.05029297,  0.20800781, -0.03857422, -0.22265625,  0.27539062,\n",
       "       -0.05957031, -0.01757812,  0.01794434,  0.08886719,  0.12890625,\n",
       "        0.18261719,  0.14453125,  0.10400391, -0.1328125 , -0.32617188,\n",
       "        0.00386047, -0.11376953, -0.05053711, -0.13085938,  0.02209473,\n",
       "       -0.14648438,  0.10742188,  0.23046875,  0.15234375,  0.22753906,\n",
       "        0.04833984,  0.06787109, -0.06787109, -0.2578125 ,  0.11230469,\n",
       "        0.00363159, -0.12011719, -0.21289062,  0.11230469,  0.12158203,\n",
       "        0.06835938,  0.04907227,  0.2734375 , -0.00302124, -0.00378418,\n",
       "        0.00193787,  0.1875    , -0.29101562,  0.09033203,  0.26367188,\n",
       "       -0.25585938, -0.28710938, -0.40820312,  0.10546875,  0.39648438,\n",
       "       -0.07275391, -0.04321289, -0.06347656, -0.00060272, -0.11523438,\n",
       "        0.31445312, -0.22265625,  0.13574219, -0.01965332,  0.15332031,\n",
       "        0.00360107, -0.12011719,  0.06494141,  0.16210938, -0.16699219,\n",
       "        0.03271484, -0.00350952,  0.18847656,  0.19335938,  0.1328125 ,\n",
       "        0.06787109, -0.34179688, -0.08349609, -0.29492188, -0.02099609,\n",
       "        0.08886719,  0.32421875, -0.36914062, -0.0859375 , -0.04956055,\n",
       "        0.13183594,  0.04418945,  0.359375  ,  0.21484375,  0.265625  ,\n",
       "       -0.2734375 ,  0.23535156,  0.11425781,  0.08789062,  0.1875    ,\n",
       "       -0.33203125,  0.15136719, -0.03613281, -0.11914062,  0.27734375,\n",
       "        0.10839844, -0.07275391,  0.23242188,  0.00219727,  0.23828125,\n",
       "       -0.24902344, -0.12353516, -0.15917969, -0.00601196,  0.14550781,\n",
       "       -0.00460815, -0.22558594, -0.37890625, -0.37695312, -0.08251953,\n",
       "       -0.04125977,  0.16796875, -0.046875  ,  0.16308594,  0.15429688],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7300517], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the woman equivalent of King ????\n",
    "a = model.get_vector('king') + model.get_vector('woman') - model.get_vector('man')\n",
    "model.cosine_similarities(a, [model.get_vector('queen')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQfDl0Q-zdlG",
    "outputId": "3b73bf88-67b2-4551-acd1-722798a9419e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674735069275), ('princess', 0.5902431011199951)]\n"
     ]
    }
   ],
   "source": [
    "# calculate: (king - man) + woman = ?  (Queen)\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cricketing', 0.657913863658905), ('Sachin', 0.6445838809013367), ('cricketers', 0.6345413327217102)]\n"
     ]
    }
   ],
   "source": [
    "# Who is the God of Cricket in India ?\n",
    "result = model.most_similar(positive=['God', 'cricket', 'India'], negative=[], topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZefKPlSzdlJ",
    "outputId": "1124a843-226b-4068-9d34-8237ba76f6b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.7685461640357971), ('teenage_girl', 0.5872832536697388), ('lady', 0.5742953419685364)]\n"
     ]
    }
   ],
   "source": [
    "# what is the female equivalent of the word \"man\"\n",
    "result = model.most_similar(positive=['man', 'female'], negative=['male'], topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuBcROkCzdlM",
    "outputId": "f3627953-9ede-49dc-c0b8-c7a21e236311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63029367\n"
     ]
    }
   ],
   "source": [
    "#Checking how similarity works. \n",
    "print (model.similarity('strawberry', 'mango'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ubg2kfWtzdlQ",
    "outputId": "66d3eada-3253-4ffc-a66f-327c5c575b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6121936\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('novel', 'book'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06800091\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('novel', 'mango'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NL-_6jrzdlU",
    "outputId": "c78a2de7-964d-4a5a-cabc-29072d8d61d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the odd one out.\n",
    "model.doesnt_match('breakfast cereal dinner lunch'.split())\n",
    "# model.doesnt_match('mango apple banana rose'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('puppy', 0.793572187423706), ('pup', 0.7656400799751282), ('kitten', 0.730669379234314)]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['dog', 'newborn'], topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OhMuEtrzdlZ"
   },
   "source": [
    "## Using Stanfordâ€™s GloVe Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vx147K1Gzdla"
   },
   "source": [
    "Stanford researchers also have their own word embedding algorithm like Word2Vec called `Global\n",
    "Vectors` for Word Representation, or `GloVe` for short. \n",
    "\n",
    "You can download the GloVe pre-trained word vectors and load them easily with `Gensim`. The first step is to convert the GloVe file format to the Word2Vec file format. The only difference is the addition of a small header line. This can be done by calling the `glove2word2vec()` function.  Once converted, the file can be loaded just like Word2Vec file above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Lw5rRlnzdlb"
   },
   "source": [
    "You can download the smallest GloVe pre-trained model from the GloVe\n",
    "website. It an 822 Megabyte zip file with 4 different models (50, 100, 200 and 300-dimensional\n",
    "vectors) trained on Wikipedia data with 6 billion tokens and a 400,000 word vocabulary. The\n",
    "direct download link is here http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuifXe-lzdlf",
    "outputId": "3c54319a-6a44-4e1c-9b46-bb947bde4d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prashant\\AppData\\Local\\Temp\\ipykernel_26916\\925924199.py:9: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# convert glove to word2vec format\n",
    "path = r'D:\\OneDrive\\Google Drive Files\\Training\\1 MASTER\\NLP new\\Word Embeddings'\n",
    "\n",
    "glove_input_file = path + '\\glove.6B.100d.txt'\n",
    "word2vec_output_file = 'word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJeH2BBZzdlp"
   },
   "outputs": [],
   "source": [
    "# load the converted model\n",
    "filename = 'word2vec.txt'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J__cMKiszdlt"
   },
   "source": [
    "You now have a copy of the `GloVe` model in `Word2Vec` format with the filename\n",
    "`glove.6B.100d.txt.word2vec`. Now we can load it and perform the same `(king - man) + woman = ?` test as in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tYXFs2Gzdlt",
    "outputId": "1567de99-06be-4ffc-858c-3bb21bc9397f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILS09f13zdlx"
   },
   "source": [
    "### Further Reading:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEzTAkbVzdlx"
   },
   "source": [
    "#### Word Embeddings\n",
    "+ Word Embedding on Wikipedia.https://en.wikipedia.org/wiki/Word2vec\n",
    "+ Word2Vec on Wikipedia. https://en.wikipedia.org/wiki/Word2vec\n",
    "+ Google Word2Vec project. https://code.google.com/archive/p/word2vec/\n",
    "+ Stanford GloVe project. https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lvt3TC8Ezdly"
   },
   "source": [
    "### Articles\n",
    "+ Messing Around With Word2Vec, 2016. https://quomodocumque.wordpress.com/2016/01/15/messing-around-with-word2vec/\n",
    "+ Vector Space Models for the Digital Humanities, 2015. http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html\n",
    "+ Gensim Word2Vec Tutorial, 2014. https://rare-technologies.com/word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7k8dO82uzdnQ"
   },
   "source": [
    "# Facebook's FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4_jRlrCzdnR"
   },
   "source": [
    "`fastText` is the improvised version of `word2vec`. `word2vec` basically considers words to build the representation. But `fastText` takes each character while computing the representation of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gVrB6fNzdnR"
   },
   "outputs": [],
   "source": [
    "sentences = [['I', 'love', 'nlp'],\n",
    "['I', 'will', 'learn', 'nlp', 'in', '2','months'],\n",
    "['nlp', 'is', 'future'],\n",
    "['nlp', 'saves', 'time', 'and', 'solves',\n",
    "'lot', 'of', 'industry', 'problems'],\n",
    "['nlp', 'uses', 'machine', 'learning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVYHFXdWzdnU"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "fast = FastText(sentences,vector_size=20, window=1, min_count=1, workers=5, min_n=1, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00718044,  0.00634451,  0.01015092,  0.00278108,  0.00071975,\n",
       "        0.01481973, -0.01144717,  0.0085934 ,  0.00387139, -0.00861204,\n",
       "       -0.01795045, -0.00222266,  0.0043997 ,  0.01099374,  0.00549521,\n",
       "       -0.02154304,  0.02005067, -0.00923354,  0.00634542,  0.00346849],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast.wv.get_vector('future')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00516996,  0.00863833,  0.00496077,  0.0065316 ,  0.01097381,\n",
       "        0.00640103,  0.0061447 ,  0.00292935, -0.00900661,  0.01208093,\n",
       "        0.00329964,  0.00117949, -0.00334365,  0.00119693,  0.0070916 ,\n",
       "       -0.00667899,  0.00937506, -0.0102112 ,  0.00654462, -0.00943527],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast.wv.get_vector('vidhya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 0,\n",
       " 'I': 1,\n",
       " 'future': 2,\n",
       " 'love': 3,\n",
       " 'will': 4,\n",
       " 'learn': 5,\n",
       " 'in': 6,\n",
       " '2': 7,\n",
       " 'months': 8,\n",
       " 'is': 9,\n",
       " 'learning': 10,\n",
       " 'machine': 11,\n",
       " 'time': 12,\n",
       " 'and': 13,\n",
       " 'solves': 14,\n",
       " 'lot': 15,\n",
       " 'of': 16,\n",
       " 'industry': 17,\n",
       " 'problems': 18,\n",
       " 'uses': 19,\n",
       " 'saves': 20}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fast.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Word Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
